{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1012a788",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/breakpoints.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239469-lesson-2-breakpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa16f5-abc8-4ed3-8a71-54837fe46917",
   "metadata": {},
   "source": [
    "# Breakpoints\n",
    "\n",
    "## Review\n",
    "\n",
    "For `human-in-the-loop`, we often want to see our graph outputs as its running. \n",
    "\n",
    "We laid the foundations for this with streaming. \n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's talk about the motivations for `human-in-the-loop`:\n",
    "\n",
    "(1) `Approval` - We can interrupt our agent, surface state to a user, and allow the user to accept an action\n",
    "\n",
    "(2) `Debugging` - We can rewind the graph to reproduce or avoid issues\n",
    "\n",
    "(3) `Editing` - You can modify the state \n",
    "\n",
    "LangGraph offers several ways to get or update agent state to support various `human-in-the-loop` workflows.\n",
    "\n",
    "First, we'll introduce [breakpoints](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/breakpoints/#simple-usage), which provide a simple way to stop the graph at specific steps. \n",
    "\n",
    "We'll show how this enables user `approval`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35842345-0694-4f0a-aa62-7d4898abf653",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk langgraph-prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d91f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../module-3/studio/.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d8b4cd-e3ff-48cc-b7b2-f83fadb1c86b",
   "metadata": {},
   "source": [
    "## Breakpoints for human approval\n",
    "\n",
    "Let's re-consider the simple agent that we worked with in Module 1. \n",
    "\n",
    "Let's assume that are concerned about tool use: we want to approve the agent to use any of its tools.\n",
    " \n",
    "All we need to do is simply compile the graph with `interrupt_before=[\"tools\"]` where `tools` is our tools node.\n",
    "\n",
    "This means that the execution will be interrupted before the node `tools`, which executes the tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b94d1a90-2fe3-4b2a-a901-3bdb89e37edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# This will be a tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a by b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac06feae-d12b-490b-95e7-38cf40b74202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine the control flow\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=[\"tools\"], checkpointer=memory)\n",
    "\n",
    "# Show\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a783efac-46a9-4fb4-a1c6-a11b02540448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_N0Sj3Pr8ZqRHKOigA4xR69Qh)\n",
      " Call ID: call_N0Sj3Pr8ZqRHKOigA4xR69Qh\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d49669-b1a5-42c2-bdb8-052da89bd7c4",
   "metadata": {},
   "source": [
    "We can get the state and look at the next node to call.\n",
    "\n",
    "This is a nice way to see that the graph has been interrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61569596-8342-4a37-9c99-e3a9dccb18ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = graph.get_state(thread)\n",
    "state.next"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fea0fb5-3145-4f34-bcc0-9c9e8972d6b4",
   "metadata": {},
   "source": [
    "Now, we'll introduce a nice trick.\n",
    "\n",
    "When we invoke the graph with `None`, it will just continue from the last state checkpoint!\n",
    "\n",
    "![breakpoints.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbae7985b747dfed67775d_breakpoints1.png)\n",
    "\n",
    "For clarity, LangGraph will re-emit the current state, which contains the `AIMessage` with tool call.\n",
    "\n",
    "And then it will proceed to execute the following steps in the graph, which start with the tool node.\n",
    "\n",
    "We see that the tool node is run with this tool call, and it's passed back to the chat model for our final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "896a5f41-7386-4bfa-a78e-3e6ca5e26641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_N0Sj3Pr8ZqRHKOigA4xR69Qh)\n",
      " Call ID: call_N0Sj3Pr8ZqRHKOigA4xR69Qh\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/pregel/main.py:2679\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2677\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2678\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2679\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2680\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2684\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2686\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2688\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2689\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36massistant\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34massistant\u001b[39m(state: MessagesState):\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m    \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[43mllm_with_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msys_msg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/runnables/base.py:5492\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5485\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5486\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5487\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5490\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5491\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5492\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5494\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5495\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5496\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:379\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    367\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    372\u001b[39m     **kwargs: Any,\n\u001b[32m    373\u001b[39m ) -> AIMessage:\n\u001b[32m    374\u001b[39m     config = ensure_config(config)\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    376\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    377\u001b[39m         cast(\n\u001b[32m    378\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    389\u001b[39m         ).message,\n\u001b[32m    390\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1088\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1079\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1080\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1081\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m     **kwargs: Any,\n\u001b[32m   1086\u001b[39m ) -> LLMResult:\n\u001b[32m   1087\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:903\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    900\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    902\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    909\u001b[39m         )\n\u001b[32m    910\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    911\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1192\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1190\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1196\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1294\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1287\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[32m   1288\u001b[39m             response,\n\u001b[32m   1289\u001b[39m             schema=original_schema_obj,\n\u001b[32m   1290\u001b[39m             metadata=generation_info,\n\u001b[32m   1291\u001b[39m             output_version=\u001b[38;5;28mself\u001b[39m.output_version,\n\u001b[32m   1292\u001b[39m         )\n\u001b[32m   1293\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1294\u001b[39m         raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1295\u001b[39m         response = raw_response.parse()\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1145\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1146\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_base_client.py:982\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    980\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    988\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1233\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1230\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1231\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1232\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1106\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f91a0c-7cc1-4437-adc7-b36abb29beb1",
   "metadata": {},
   "source": [
    "Now, lets bring these together with a specific user approval step that accepts user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a0eb50-66e3-4538-8103-207aae175154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_JdqzP3VUshBy7xxPwYBV00CX)\n",
      " Call ID: call_JdqzP3VUshBy7xxPwYBV00CX\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "Operation cancelled by user.\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()\n",
    "\n",
    "# Get user feedback\n",
    "user_approval = input(\"Do you want to call the tool? (yes/no): \")\n",
    "\n",
    "# Check approval\n",
    "if user_approval.lower() == \"yes\":\n",
    "    \n",
    "    # If approved, continue the graph execution\n",
    "    for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "        event['messages'][-1].pretty_print()\n",
    "        \n",
    "else:\n",
    "    \n",
    "    print(\"Operation cancelled by user.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8ff8762-6fa1-4373-954a-e7f479ee0efb",
   "metadata": {},
   "source": [
    "### Breakpoints with LangGraph API\n",
    "\n",
    "**⚠️ DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "- 🚀 API: http://127.0.0.1:2024\n",
    "- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- 📚 API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
    "\n",
    "The LangGraph API [supports breakpoints](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_breakpoint/#sdk-initialization). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c2eaf1-6b8b-4d80-9902-98ae5587bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1dd890-c216-4802-9e33-b637e491e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the URL of the local development server\n",
    "from langgraph_sdk import get_client\n",
    "client = get_client(url=\"http://127.0.0.1:2024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80d969-d065-45d7-8bfc-a403a0a1079b",
   "metadata": {},
   "source": [
    "As shown above, we can add `interrupt_before=[\"node\"]` when compiling the graph that is running in Studio.\n",
    "\n",
    "However, with the API, you can also pass `interrupt_before` to the stream method directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9c5017-3a15-46f6-8edf-3997613da323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '256659f9-7b62-4811-9077-482baddb1051', 'example': False}\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'call_S7RP7F6qz34TrennPJ7HkLWe', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 17, 'prompt_tokens': 134, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CVIiuEQidGbSnupDRddPlwh7Sr0wt', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--438b454a-0dfe-4bc0-b913-28843be955d8-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_S7RP7F6qz34TrennPJ7HkLWe', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 17, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "thread = await client.threads.create()\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input=initial_input,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"tools\"],\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    messages = chunk.data.get('messages', [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64272d1-c6ee-435f-9890-9b6c3525ca6c",
   "metadata": {},
   "source": [
    "Now, we can proceed from the breakpoint just like we did before by passing the `thread_id` and `None` as the input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76284730-9c90-46c4-8295-400a49760b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'call_S7RP7F6qz34TrennPJ7HkLWe', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 17, 'prompt_tokens': 134, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CVIiuEQidGbSnupDRddPlwh7Sr0wt', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--438b454a-0dfe-4bc0-b913-28843be955d8-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_S7RP7F6qz34TrennPJ7HkLWe', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 17, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '7270c7b4-9e19-4e9a-a639-575e5242d6a5', 'tool_call_id': 'call_S7RP7F6qz34TrennPJ7HkLWe', 'artifact': None, 'status': 'success'}\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 14, 'prompt_tokens': 159, 'total_tokens': 173, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CVIiwEbxQPQXZYajVZ3FiItWJQSah', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--b5e92bdd-dd96-474b-8601-0d85f0918b45-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 159, 'output_tokens': 14, 'total_tokens': 173, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    \"agent\",\n",
    "    input=None,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"tools\"],\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    messages = chunk.data.get('messages', [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4575970f-42e2-4d03-b18a-aacaa8233b53",
   "metadata": {},
   "source": [
    "# Tweaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cef762e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 5 and 10\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_ts5GZ3NRCBS44SLyp05Rdfg1)\n",
      " Call ID: call_ts5GZ3NRCBS44SLyp05Rdfg1\n",
      "  Args:\n",
      "    a: 5\n",
      "    b: 10\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": HumanMessage(content=\"Add 5 and 10\")}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf668afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 5 and 10\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_Pqo5wHjXxlSkpd0hFvHyL9lV)\n",
      " Call ID: call_Pqo5wHjXxlSkpd0hFvHyL9lV\n",
      "  Args:\n",
      "    a: 5\n",
      "    b: 10\n",
      "Operation cancelled by user.\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": HumanMessage(content=\"Add 5 and 10\")}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()\n",
    "\n",
    "# Get user feedback\n",
    "user_approval = input(\"Do you want to call the tool? (yes/no): \")\n",
    "\n",
    "# Check approval\n",
    "if user_approval.lower() == \"yes\":\n",
    "    \n",
    "    # If approved, continue the graph execution\n",
    "    for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "        event['messages'][-1].pretty_print()\n",
    "        \n",
    "else:\n",
    "    \n",
    "    print(\"Operation cancelled by user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b4d4205",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m initial_input = {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mAdd 5 and 10\u001b[39m\u001b[33m\"\u001b[39m)}\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m thread = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mclient\u001b[49m.threads.create()\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m client.runs.stream(\n\u001b[32m      4\u001b[39m     thread[\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      5\u001b[39m     assistant_id=\u001b[33m\"\u001b[39m\u001b[33magent\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     interrupt_before=[\u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      9\u001b[39m ):\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceiving new event of type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk.event\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "initial_input = {\"messages\": HumanMessage(content=\"Add 5 and 10\")}\n",
    "thread = await client.threads.create()\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input=initial_input,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"tools\"],\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    messages = chunk.data.get('messages', [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
